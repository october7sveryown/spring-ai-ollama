spring.application.name=ollama-ai

spring.ai.ollama.base-url=http://localhost:11434

#you can use whatever model you like
spring.ai.ollama.chat.options.model=dolphin-phi

#this is optional
spring.ai.ollama.chat.options.temperature=0.7
